<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>reinforcement learning on RuChen Xu's Blog</title><link>http://localhost:1313/tags/reinforcement-learning/</link><description>Recent content in reinforcement learning on RuChen Xu's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 24 Aug 2020 16:00:06 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>cs285 DRL notes chapter 3: policy gradient methods</title><link>http://localhost:1313/post/cs285_chapter3/cs285-drl-notes-chapter-3-policy-gradient-methods/</link><pubDate>Mon, 24 Aug 2020 16:00:06 +0000</pubDate><guid>http://localhost:1313/post/cs285_chapter3/cs285-drl-notes-chapter-3-policy-gradient-methods/</guid><description>回顾强化学习的目标，我们希望获得策略的最优参数$\theta^$， $$ \theta^=\underset{\theta}{argmax}\mathbb{E}{\tau\sim p{\theta}(\tau)}[\sum_{t=1}^{t=T}r(s_t, a_t)] $$ 这实际上是一个优化问题，因此我们可以使用多种优化方法来优化这个目</description></item><item><title>cs285 DRL notes chapter 2: imitation learning</title><link>http://localhost:1313/post/cs285_chapter2/cs285-drl-notes-chapter-2-imitation-learning/</link><pubDate>Sun, 23 Aug 2020 15:13:48 +0000</pubDate><guid>http://localhost:1313/post/cs285_chapter2/cs285-drl-notes-chapter-2-imitation-learning/</guid><description>模仿学习是一种监督学习方法，行为克隆是其中的一类方法。其基本思想是从专家演示数据中学习到一个尽可能接近专家策略的行为策略。我们的数据集是依据</description></item><item><title>cs285 DRL notes chapter 1: introduction</title><link>http://localhost:1313/post/cs285_chapter1/cs285-drl-notes-chapter-1-introduction/</link><pubDate>Mon, 03 Aug 2020 10:58:41 +0000</pubDate><guid>http://localhost:1313/post/cs285_chapter1/cs285-drl-notes-chapter-1-introduction/</guid><description>强化学习是一种目标导向的学习方法，通过不断试错，奖励或惩罚智能体从而使其未来更容易重复或者放弃某一动作。 强化学习中的术语介绍。 强化学习的主要</description></item></channel></rss>